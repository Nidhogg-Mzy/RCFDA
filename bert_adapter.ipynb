{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zmengaf/miniconda3/envs/rcfda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "import torch\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import adapters\n",
    "from adapters import init, AutoAdapterModel, BnConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load('/data/zmengaf/5212/RCFDA/bert_model_arxiv_acc_0.8027633851468048.pt')\n",
    "model.classifier = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2).to(device).classifier\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttentionWithAdapters(\n",
       "              (query): LoRALinear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (key): LoRALinear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (value): LoRALinear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (prefix_tuning): PrefixTuningLayer(\n",
       "                (prefix_gates): ModuleDict()\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (output): BertSelfOutputWithAdapters(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (adapters): ModuleDict(\n",
       "                (arxiv): Adapter(\n",
       "                  (non_linearity): Activation_Function_Class(\n",
       "                    (f): ReLU()\n",
       "                  )\n",
       "                  (adapter_down): Sequential(\n",
       "                    (0): Linear(in_features=768, out_features=8, bias=True)\n",
       "                    (1): Activation_Function_Class(\n",
       "                      (f): ReLU()\n",
       "                    )\n",
       "                  )\n",
       "                  (adapter_up): Linear(in_features=8, out_features=768, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): LoRALinear(\n",
       "              in_features=768, out_features=3072, bias=True\n",
       "              (loras): ModuleDict()\n",
       "            )\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutputWithAdapters(\n",
       "            (dense): LoRALinear(\n",
       "              in_features=3072, out_features=768, bias=True\n",
       "              (loras): ModuleDict()\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (adapters): ModuleDict(\n",
       "              (arxiv): Adapter(\n",
       "                (non_linearity): Activation_Function_Class(\n",
       "                  (f): ReLU()\n",
       "                )\n",
       "                (adapter_down): Sequential(\n",
       "                  (0): Linear(in_features=768, out_features=8, bias=True)\n",
       "                  (1): Activation_Function_Class(\n",
       "                    (f): ReLU()\n",
       "                  )\n",
       "                )\n",
       "                (adapter_up): Linear(in_features=8, out_features=768, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (adapter_fusion_layer): ModuleDict()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "    (shared_parameters): ModuleDict()\n",
       "    (invertible_adapters): ModuleDict()\n",
       "    (prefix_tuning): PrefixTuningPool(\n",
       "      (prefix_tunings): ModuleDict()\n",
       "    )\n",
       "    (prompt_tuning): PromptTuningLayer(\n",
       "      (base_model_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (prompt_tunings): ModuleDict()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adapters.init(model)\n",
    "config = BnConfig(mh_adapter=True, output_adapter=True, reduction_factor=96, non_linearity=\"relu\")\n",
    "model.add_adapter(\"arxiv\", config=config)\n",
    "model.train_adapter(\"arxiv\")\n",
    "model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.num_labels = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(model.num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_status(model):\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            print(name + \" is trainable\")\n",
    "        else:\n",
    "            print(name + \" is frozen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert.embeddings.word_embeddings.weight is frozen\n",
      "bert.embeddings.position_embeddings.weight is frozen\n",
      "bert.embeddings.token_type_embeddings.weight is frozen\n",
      "bert.embeddings.LayerNorm.weight is frozen\n",
      "bert.embeddings.LayerNorm.bias is frozen\n",
      "bert.encoder.layer.0.attention.self.query.weight is frozen\n",
      "bert.encoder.layer.0.attention.self.query.bias is frozen\n",
      "bert.encoder.layer.0.attention.self.key.weight is frozen\n",
      "bert.encoder.layer.0.attention.self.key.bias is frozen\n",
      "bert.encoder.layer.0.attention.self.value.weight is frozen\n",
      "bert.encoder.layer.0.attention.self.value.bias is frozen\n",
      "bert.encoder.layer.0.attention.output.dense.weight is frozen\n",
      "bert.encoder.layer.0.attention.output.dense.bias is frozen\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight is frozen\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias is frozen\n",
      "bert.encoder.layer.0.attention.output.adapters.arxiv.adapter_down.0.weight is trainable\n",
      "bert.encoder.layer.0.attention.output.adapters.arxiv.adapter_down.0.bias is trainable\n",
      "bert.encoder.layer.0.attention.output.adapters.arxiv.adapter_up.weight is trainable\n",
      "bert.encoder.layer.0.attention.output.adapters.arxiv.adapter_up.bias is trainable\n",
      "bert.encoder.layer.0.intermediate.dense.weight is frozen\n",
      "bert.encoder.layer.0.intermediate.dense.bias is frozen\n",
      "bert.encoder.layer.0.output.dense.weight is frozen\n",
      "bert.encoder.layer.0.output.dense.bias is frozen\n",
      "bert.encoder.layer.0.output.LayerNorm.weight is frozen\n",
      "bert.encoder.layer.0.output.LayerNorm.bias is frozen\n",
      "bert.encoder.layer.0.output.adapters.arxiv.adapter_down.0.weight is trainable\n",
      "bert.encoder.layer.0.output.adapters.arxiv.adapter_down.0.bias is trainable\n",
      "bert.encoder.layer.0.output.adapters.arxiv.adapter_up.weight is trainable\n",
      "bert.encoder.layer.0.output.adapters.arxiv.adapter_up.bias is trainable\n",
      "bert.encoder.layer.1.attention.self.query.weight is frozen\n",
      "bert.encoder.layer.1.attention.self.query.bias is frozen\n",
      "bert.encoder.layer.1.attention.self.key.weight is frozen\n",
      "bert.encoder.layer.1.attention.self.key.bias is frozen\n",
      "bert.encoder.layer.1.attention.self.value.weight is frozen\n",
      "bert.encoder.layer.1.attention.self.value.bias is frozen\n",
      "bert.encoder.layer.1.attention.output.dense.weight is frozen\n",
      "bert.encoder.layer.1.attention.output.dense.bias is frozen\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.weight is frozen\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.bias is frozen\n",
      "bert.encoder.layer.1.attention.output.adapters.arxiv.adapter_down.0.weight is trainable\n",
      "bert.encoder.layer.1.attention.output.adapters.arxiv.adapter_down.0.bias is trainable\n",
      "bert.encoder.layer.1.attention.output.adapters.arxiv.adapter_up.weight is trainable\n",
      "bert.encoder.layer.1.attention.output.adapters.arxiv.adapter_up.bias is trainable\n",
      "bert.encoder.layer.1.intermediate.dense.weight is frozen\n",
      "bert.encoder.layer.1.intermediate.dense.bias is frozen\n",
      "bert.encoder.layer.1.output.dense.weight is frozen\n",
      "bert.encoder.layer.1.output.dense.bias is frozen\n",
      "bert.encoder.layer.1.output.LayerNorm.weight is frozen\n",
      "bert.encoder.layer.1.output.LayerNorm.bias is frozen\n",
      "bert.encoder.layer.1.output.adapters.arxiv.adapter_down.0.weight is trainable\n",
      "bert.encoder.layer.1.output.adapters.arxiv.adapter_down.0.bias is trainable\n",
      "bert.encoder.layer.1.output.adapters.arxiv.adapter_up.weight is trainable\n",
      "bert.encoder.layer.1.output.adapters.arxiv.adapter_up.bias is trainable\n",
      "bert.encoder.layer.2.attention.self.query.weight is frozen\n",
      "bert.encoder.layer.2.attention.self.query.bias is frozen\n",
      "bert.encoder.layer.2.attention.self.key.weight is frozen\n",
      "bert.encoder.layer.2.attention.self.key.bias is frozen\n",
      "bert.encoder.layer.2.attention.self.value.weight is frozen\n",
      "bert.encoder.layer.2.attention.self.value.bias is frozen\n",
      "bert.encoder.layer.2.attention.output.dense.weight is frozen\n",
      "bert.encoder.layer.2.attention.output.dense.bias is frozen\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.weight is frozen\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.bias is frozen\n",
      "bert.encoder.layer.2.attention.output.adapters.arxiv.adapter_down.0.weight is trainable\n",
      "bert.encoder.layer.2.attention.output.adapters.arxiv.adapter_down.0.bias is trainable\n",
      "bert.encoder.layer.2.attention.output.adapters.arxiv.adapter_up.weight is trainable\n",
      "bert.encoder.layer.2.attention.output.adapters.arxiv.adapter_up.bias is trainable\n",
      "bert.encoder.layer.2.intermediate.dense.weight is frozen\n",
      "bert.encoder.layer.2.intermediate.dense.bias is frozen\n",
      "bert.encoder.layer.2.output.dense.weight is frozen\n",
      "bert.encoder.layer.2.output.dense.bias is frozen\n",
      "bert.encoder.layer.2.output.LayerNorm.weight is frozen\n",
      "bert.encoder.layer.2.output.LayerNorm.bias is frozen\n",
      "bert.encoder.layer.2.output.adapters.arxiv.adapter_down.0.weight is trainable\n",
      "bert.encoder.layer.2.output.adapters.arxiv.adapter_down.0.bias is trainable\n",
      "bert.encoder.layer.2.output.adapters.arxiv.adapter_up.weight is trainable\n",
      "bert.encoder.layer.2.output.adapters.arxiv.adapter_up.bias is trainable\n",
      "bert.encoder.layer.3.attention.self.query.weight is frozen\n",
      "bert.encoder.layer.3.attention.self.query.bias is frozen\n",
      "bert.encoder.layer.3.attention.self.key.weight is frozen\n",
      "bert.encoder.layer.3.attention.self.key.bias is frozen\n",
      "bert.encoder.layer.3.attention.self.value.weight is frozen\n",
      "bert.encoder.layer.3.attention.self.value.bias is frozen\n",
      "bert.encoder.layer.3.attention.output.dense.weight is frozen\n",
      "bert.encoder.layer.3.attention.output.dense.bias is frozen\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.weight is frozen\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.bias is frozen\n",
      "bert.encoder.layer.3.attention.output.adapters.arxiv.adapter_down.0.weight is trainable\n",
      "bert.encoder.layer.3.attention.output.adapters.arxiv.adapter_down.0.bias is trainable\n",
      "bert.encoder.layer.3.attention.output.adapters.arxiv.adapter_up.weight is trainable\n",
      "bert.encoder.layer.3.attention.output.adapters.arxiv.adapter_up.bias is trainable\n",
      "bert.encoder.layer.3.intermediate.dense.weight is frozen\n",
      "bert.encoder.layer.3.intermediate.dense.bias is frozen\n",
      "bert.encoder.layer.3.output.dense.weight is frozen\n",
      "bert.encoder.layer.3.output.dense.bias is frozen\n",
      "bert.encoder.layer.3.output.LayerNorm.weight is frozen\n",
      "bert.encoder.layer.3.output.LayerNorm.bias is frozen\n",
      "bert.encoder.layer.3.output.adapters.arxiv.adapter_down.0.weight is trainable\n",
      "bert.encoder.layer.3.output.adapters.arxiv.adapter_down.0.bias is trainable\n",
      "bert.encoder.layer.3.output.adapters.arxiv.adapter_up.weight is trainable\n",
      "bert.encoder.layer.3.output.adapters.arxiv.adapter_up.bias is trainable\n",
      "bert.encoder.layer.4.attention.self.query.weight is frozen\n",
      "bert.encoder.layer.4.attention.self.query.bias is frozen\n",
      "bert.encoder.layer.4.attention.self.key.weight is frozen\n",
      "bert.encoder.layer.4.attention.self.key.bias is frozen\n",
      "bert.encoder.layer.4.attention.self.value.weight is frozen\n",
      "bert.encoder.layer.4.attention.self.value.bias is frozen\n",
      "bert.encoder.layer.4.attention.output.dense.weight is frozen\n",
      "bert.encoder.layer.4.attention.output.dense.bias is frozen\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.weight is frozen\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.bias is frozen\n",
      "bert.encoder.layer.4.attention.output.adapters.arxiv.adapter_down.0.weight is trainable\n",
      "bert.encoder.layer.4.attention.output.adapters.arxiv.adapter_down.0.bias is trainable\n",
      "bert.encoder.layer.4.attention.output.adapters.arxiv.adapter_up.weight is trainable\n",
      "bert.encoder.layer.4.attention.output.adapters.arxiv.adapter_up.bias is trainable\n",
      "bert.encoder.layer.4.intermediate.dense.weight is frozen\n",
      "bert.encoder.layer.4.intermediate.dense.bias is frozen\n",
      "bert.encoder.layer.4.output.dense.weight is frozen\n",
      "bert.encoder.layer.4.output.dense.bias is frozen\n",
      "bert.encoder.layer.4.output.LayerNorm.weight is frozen\n",
      "bert.encoder.layer.4.output.LayerNorm.bias is frozen\n",
      "bert.encoder.layer.4.output.adapters.arxiv.adapter_down.0.weight is trainable\n",
      "bert.encoder.layer.4.output.adapters.arxiv.adapter_down.0.bias is trainable\n",
      "bert.encoder.layer.4.output.adapters.arxiv.adapter_up.weight is trainable\n",
      "bert.encoder.layer.4.output.adapters.arxiv.adapter_up.bias is trainable\n",
      "bert.encoder.layer.5.attention.self.query.weight is frozen\n",
      "bert.encoder.layer.5.attention.self.query.bias is frozen\n",
      "bert.encoder.layer.5.attention.self.key.weight is frozen\n",
      "bert.encoder.layer.5.attention.self.key.bias is frozen\n",
      "bert.encoder.layer.5.attention.self.value.weight is frozen\n",
      "bert.encoder.layer.5.attention.self.value.bias is frozen\n",
      "bert.encoder.layer.5.attention.output.dense.weight is frozen\n",
      "bert.encoder.layer.5.attention.output.dense.bias is frozen\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.weight is frozen\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.bias is frozen\n",
      "bert.encoder.layer.5.attention.output.adapters.arxiv.adapter_down.0.weight is trainable\n",
      "bert.encoder.layer.5.attention.output.adapters.arxiv.adapter_down.0.bias is trainable\n",
      "bert.encoder.layer.5.attention.output.adapters.arxiv.adapter_up.weight is trainable\n",
      "bert.encoder.layer.5.attention.output.adapters.arxiv.adapter_up.bias is trainable\n",
      "bert.encoder.layer.5.intermediate.dense.weight is frozen\n",
      "bert.encoder.layer.5.intermediate.dense.bias is frozen\n",
      "bert.encoder.layer.5.output.dense.weight is frozen\n",
      "bert.encoder.layer.5.output.dense.bias is frozen\n",
      "bert.encoder.layer.5.output.LayerNorm.weight is frozen\n",
      "bert.encoder.layer.5.output.LayerNorm.bias is frozen\n",
      "bert.encoder.layer.5.output.adapters.arxiv.adapter_down.0.weight is trainable\n",
      "bert.encoder.layer.5.output.adapters.arxiv.adapter_down.0.bias is trainable\n",
      "bert.encoder.layer.5.output.adapters.arxiv.adapter_up.weight is trainable\n",
      "bert.encoder.layer.5.output.adapters.arxiv.adapter_up.bias is trainable\n",
      "bert.encoder.layer.6.attention.self.query.weight is frozen\n",
      "bert.encoder.layer.6.attention.self.query.bias is frozen\n",
      "bert.encoder.layer.6.attention.self.key.weight is frozen\n",
      "bert.encoder.layer.6.attention.self.key.bias is frozen\n",
      "bert.encoder.layer.6.attention.self.value.weight is frozen\n",
      "bert.encoder.layer.6.attention.self.value.bias is frozen\n",
      "bert.encoder.layer.6.attention.output.dense.weight is frozen\n",
      "bert.encoder.layer.6.attention.output.dense.bias is frozen\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.weight is frozen\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.bias is frozen\n",
      "bert.encoder.layer.6.attention.output.adapters.arxiv.adapter_down.0.weight is trainable\n",
      "bert.encoder.layer.6.attention.output.adapters.arxiv.adapter_down.0.bias is trainable\n",
      "bert.encoder.layer.6.attention.output.adapters.arxiv.adapter_up.weight is trainable\n",
      "bert.encoder.layer.6.attention.output.adapters.arxiv.adapter_up.bias is trainable\n",
      "bert.encoder.layer.6.intermediate.dense.weight is frozen\n",
      "bert.encoder.layer.6.intermediate.dense.bias is frozen\n",
      "bert.encoder.layer.6.output.dense.weight is frozen\n",
      "bert.encoder.layer.6.output.dense.bias is frozen\n",
      "bert.encoder.layer.6.output.LayerNorm.weight is frozen\n",
      "bert.encoder.layer.6.output.LayerNorm.bias is frozen\n",
      "bert.encoder.layer.6.output.adapters.arxiv.adapter_down.0.weight is trainable\n",
      "bert.encoder.layer.6.output.adapters.arxiv.adapter_down.0.bias is trainable\n",
      "bert.encoder.layer.6.output.adapters.arxiv.adapter_up.weight is trainable\n",
      "bert.encoder.layer.6.output.adapters.arxiv.adapter_up.bias is trainable\n",
      "bert.encoder.layer.7.attention.self.query.weight is frozen\n",
      "bert.encoder.layer.7.attention.self.query.bias is frozen\n",
      "bert.encoder.layer.7.attention.self.key.weight is frozen\n",
      "bert.encoder.layer.7.attention.self.key.bias is frozen\n",
      "bert.encoder.layer.7.attention.self.value.weight is frozen\n",
      "bert.encoder.layer.7.attention.self.value.bias is frozen\n",
      "bert.encoder.layer.7.attention.output.dense.weight is frozen\n",
      "bert.encoder.layer.7.attention.output.dense.bias is frozen\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.weight is frozen\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.bias is frozen\n",
      "bert.encoder.layer.7.attention.output.adapters.arxiv.adapter_down.0.weight is trainable\n",
      "bert.encoder.layer.7.attention.output.adapters.arxiv.adapter_down.0.bias is trainable\n",
      "bert.encoder.layer.7.attention.output.adapters.arxiv.adapter_up.weight is trainable\n",
      "bert.encoder.layer.7.attention.output.adapters.arxiv.adapter_up.bias is trainable\n",
      "bert.encoder.layer.7.intermediate.dense.weight is frozen\n",
      "bert.encoder.layer.7.intermediate.dense.bias is frozen\n",
      "bert.encoder.layer.7.output.dense.weight is frozen\n",
      "bert.encoder.layer.7.output.dense.bias is frozen\n",
      "bert.encoder.layer.7.output.LayerNorm.weight is frozen\n",
      "bert.encoder.layer.7.output.LayerNorm.bias is frozen\n",
      "bert.encoder.layer.7.output.adapters.arxiv.adapter_down.0.weight is trainable\n",
      "bert.encoder.layer.7.output.adapters.arxiv.adapter_down.0.bias is trainable\n",
      "bert.encoder.layer.7.output.adapters.arxiv.adapter_up.weight is trainable\n",
      "bert.encoder.layer.7.output.adapters.arxiv.adapter_up.bias is trainable\n",
      "bert.encoder.layer.8.attention.self.query.weight is frozen\n",
      "bert.encoder.layer.8.attention.self.query.bias is frozen\n",
      "bert.encoder.layer.8.attention.self.key.weight is frozen\n",
      "bert.encoder.layer.8.attention.self.key.bias is frozen\n",
      "bert.encoder.layer.8.attention.self.value.weight is frozen\n",
      "bert.encoder.layer.8.attention.self.value.bias is frozen\n",
      "bert.encoder.layer.8.attention.output.dense.weight is frozen\n",
      "bert.encoder.layer.8.attention.output.dense.bias is frozen\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.weight is frozen\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.bias is frozen\n",
      "bert.encoder.layer.8.attention.output.adapters.arxiv.adapter_down.0.weight is trainable\n",
      "bert.encoder.layer.8.attention.output.adapters.arxiv.adapter_down.0.bias is trainable\n",
      "bert.encoder.layer.8.attention.output.adapters.arxiv.adapter_up.weight is trainable\n",
      "bert.encoder.layer.8.attention.output.adapters.arxiv.adapter_up.bias is trainable\n",
      "bert.encoder.layer.8.intermediate.dense.weight is frozen\n",
      "bert.encoder.layer.8.intermediate.dense.bias is frozen\n",
      "bert.encoder.layer.8.output.dense.weight is frozen\n",
      "bert.encoder.layer.8.output.dense.bias is frozen\n",
      "bert.encoder.layer.8.output.LayerNorm.weight is frozen\n",
      "bert.encoder.layer.8.output.LayerNorm.bias is frozen\n",
      "bert.encoder.layer.8.output.adapters.arxiv.adapter_down.0.weight is trainable\n",
      "bert.encoder.layer.8.output.adapters.arxiv.adapter_down.0.bias is trainable\n",
      "bert.encoder.layer.8.output.adapters.arxiv.adapter_up.weight is trainable\n",
      "bert.encoder.layer.8.output.adapters.arxiv.adapter_up.bias is trainable\n",
      "bert.encoder.layer.9.attention.self.query.weight is frozen\n",
      "bert.encoder.layer.9.attention.self.query.bias is frozen\n",
      "bert.encoder.layer.9.attention.self.key.weight is frozen\n",
      "bert.encoder.layer.9.attention.self.key.bias is frozen\n",
      "bert.encoder.layer.9.attention.self.value.weight is frozen\n",
      "bert.encoder.layer.9.attention.self.value.bias is frozen\n",
      "bert.encoder.layer.9.attention.output.dense.weight is frozen\n",
      "bert.encoder.layer.9.attention.output.dense.bias is frozen\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.weight is frozen\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.bias is frozen\n",
      "bert.encoder.layer.9.attention.output.adapters.arxiv.adapter_down.0.weight is trainable\n",
      "bert.encoder.layer.9.attention.output.adapters.arxiv.adapter_down.0.bias is trainable\n",
      "bert.encoder.layer.9.attention.output.adapters.arxiv.adapter_up.weight is trainable\n",
      "bert.encoder.layer.9.attention.output.adapters.arxiv.adapter_up.bias is trainable\n",
      "bert.encoder.layer.9.intermediate.dense.weight is frozen\n",
      "bert.encoder.layer.9.intermediate.dense.bias is frozen\n",
      "bert.encoder.layer.9.output.dense.weight is frozen\n",
      "bert.encoder.layer.9.output.dense.bias is frozen\n",
      "bert.encoder.layer.9.output.LayerNorm.weight is frozen\n",
      "bert.encoder.layer.9.output.LayerNorm.bias is frozen\n",
      "bert.encoder.layer.9.output.adapters.arxiv.adapter_down.0.weight is trainable\n",
      "bert.encoder.layer.9.output.adapters.arxiv.adapter_down.0.bias is trainable\n",
      "bert.encoder.layer.9.output.adapters.arxiv.adapter_up.weight is trainable\n",
      "bert.encoder.layer.9.output.adapters.arxiv.adapter_up.bias is trainable\n",
      "bert.encoder.layer.10.attention.self.query.weight is frozen\n",
      "bert.encoder.layer.10.attention.self.query.bias is frozen\n",
      "bert.encoder.layer.10.attention.self.key.weight is frozen\n",
      "bert.encoder.layer.10.attention.self.key.bias is frozen\n",
      "bert.encoder.layer.10.attention.self.value.weight is frozen\n",
      "bert.encoder.layer.10.attention.self.value.bias is frozen\n",
      "bert.encoder.layer.10.attention.output.dense.weight is frozen\n",
      "bert.encoder.layer.10.attention.output.dense.bias is frozen\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.weight is frozen\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.bias is frozen\n",
      "bert.encoder.layer.10.attention.output.adapters.arxiv.adapter_down.0.weight is trainable\n",
      "bert.encoder.layer.10.attention.output.adapters.arxiv.adapter_down.0.bias is trainable\n",
      "bert.encoder.layer.10.attention.output.adapters.arxiv.adapter_up.weight is trainable\n",
      "bert.encoder.layer.10.attention.output.adapters.arxiv.adapter_up.bias is trainable\n",
      "bert.encoder.layer.10.intermediate.dense.weight is frozen\n",
      "bert.encoder.layer.10.intermediate.dense.bias is frozen\n",
      "bert.encoder.layer.10.output.dense.weight is frozen\n",
      "bert.encoder.layer.10.output.dense.bias is frozen\n",
      "bert.encoder.layer.10.output.LayerNorm.weight is frozen\n",
      "bert.encoder.layer.10.output.LayerNorm.bias is frozen\n",
      "bert.encoder.layer.10.output.adapters.arxiv.adapter_down.0.weight is trainable\n",
      "bert.encoder.layer.10.output.adapters.arxiv.adapter_down.0.bias is trainable\n",
      "bert.encoder.layer.10.output.adapters.arxiv.adapter_up.weight is trainable\n",
      "bert.encoder.layer.10.output.adapters.arxiv.adapter_up.bias is trainable\n",
      "bert.encoder.layer.11.attention.self.query.weight is frozen\n",
      "bert.encoder.layer.11.attention.self.query.bias is frozen\n",
      "bert.encoder.layer.11.attention.self.key.weight is frozen\n",
      "bert.encoder.layer.11.attention.self.key.bias is frozen\n",
      "bert.encoder.layer.11.attention.self.value.weight is frozen\n",
      "bert.encoder.layer.11.attention.self.value.bias is frozen\n",
      "bert.encoder.layer.11.attention.output.dense.weight is frozen\n",
      "bert.encoder.layer.11.attention.output.dense.bias is frozen\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.weight is frozen\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.bias is frozen\n",
      "bert.encoder.layer.11.attention.output.adapters.arxiv.adapter_down.0.weight is trainable\n",
      "bert.encoder.layer.11.attention.output.adapters.arxiv.adapter_down.0.bias is trainable\n",
      "bert.encoder.layer.11.attention.output.adapters.arxiv.adapter_up.weight is trainable\n",
      "bert.encoder.layer.11.attention.output.adapters.arxiv.adapter_up.bias is trainable\n",
      "bert.encoder.layer.11.intermediate.dense.weight is frozen\n",
      "bert.encoder.layer.11.intermediate.dense.bias is frozen\n",
      "bert.encoder.layer.11.output.dense.weight is frozen\n",
      "bert.encoder.layer.11.output.dense.bias is frozen\n",
      "bert.encoder.layer.11.output.LayerNorm.weight is frozen\n",
      "bert.encoder.layer.11.output.LayerNorm.bias is frozen\n",
      "bert.encoder.layer.11.output.adapters.arxiv.adapter_down.0.weight is trainable\n",
      "bert.encoder.layer.11.output.adapters.arxiv.adapter_down.0.bias is trainable\n",
      "bert.encoder.layer.11.output.adapters.arxiv.adapter_up.weight is trainable\n",
      "bert.encoder.layer.11.output.adapters.arxiv.adapter_up.bias is trainable\n",
      "bert.pooler.dense.weight is frozen\n",
      "bert.pooler.dense.bias is frozen\n",
      "classifier.weight is trainable\n",
      "classifier.bias is trainable\n"
     ]
    }
   ],
   "source": [
    "print_trainable_status(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 25000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 25000\n",
      "    })\n",
      "    unsupervised: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 50000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"imdb\")\n",
    "print(dataset)\n",
    "imdb_test = dataset['test']\n",
    "imdb_train = dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bert-base-cased, tokenize\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# Train on IMDB dataset\n",
    "imdb_train_encodings = tokenizer(list(imdb_train['text']), truncation=True, padding=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0,  ..., 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "imdb_train_labels = torch.tensor(list(imdb_train['label']))\n",
    "imdb_train_dataset = TensorDataset(torch.tensor(imdb_train_encodings['input_ids']),\n",
    "                                   torch.tensor(imdb_train_encodings['attention_mask']),\n",
    "                                   imdb_train_labels)\n",
    "imdb_train_loader = DataLoader(imdb_train_dataset, batch_size=16, shuffle=True)\n",
    "print(imdb_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on IMDB dataset\n",
    "imdb_test_encodings = tokenizer(list(imdb_test['text']), truncation=True, padding=True)\n",
    "imdb_test_labels = torch.tensor(list(imdb_test['label']))\n",
    "imdb_test_dataset = TensorDataset(torch.tensor(imdb_test_encodings['input_ids']),\n",
    "                                  torch.tensor(imdb_test_encodings['attention_mask']),\n",
    "                                  imdb_test_labels)\n",
    "imdb_test_loader = DataLoader(imdb_test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zmengaf/miniconda3/envs/rcfda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=0.6583, train_accuracy=0.6057, test_accuracy=0.7216\n",
      "Epoch 2: train_loss=0.4238, train_accuracy=0.8128, test_accuracy=0.8628\n",
      "Epoch 3: train_loss=0.3284, train_accuracy=0.8617, test_accuracy=0.8808\n",
      "Epoch 4: train_loss=0.2999, train_accuracy=0.8779, test_accuracy=0.8856\n",
      "Epoch 5: train_loss=0.2824, train_accuracy=0.8857, test_accuracy=0.8958\n",
      "Epoch 6: train_loss=0.2703, train_accuracy=0.8901, test_accuracy=0.8981\n",
      "Epoch 7: train_loss=0.2618, train_accuracy=0.8962, test_accuracy=0.9047\n",
      "Epoch 8: train_loss=0.2538, train_accuracy=0.8979, test_accuracy=0.9076\n",
      "Epoch 9: train_loss=0.2457, train_accuracy=0.9011, test_accuracy=0.9088\n",
      "Epoch 10: train_loss=0.2405, train_accuracy=0.9063, test_accuracy=0.9100\n"
     ]
    },
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <class 'abc.BertForSequenceClassification'>: attribute lookup BertForSequenceClassification on abc failed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 39\u001b[0m\n\u001b[1;32m     36\u001b[0m         test_accuracies\u001b[38;5;241m.\u001b[39mappend(test_accuracy)\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: train_loss=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, train_accuracy=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, test_accuracy=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 39\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43madapter_bert_arxiv.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rcfda/lib/python3.10/site-packages/torch/serialization.py:619\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[1;32m    618\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m--> 619\u001b[0m         \u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_disable_byteorder_record\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    620\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    621\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/rcfda/lib/python3.10/site-packages/torch/serialization.py:831\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    829\u001b[0m pickler \u001b[38;5;241m=\u001b[39m pickle_module\u001b[38;5;241m.\u001b[39mPickler(data_buf, protocol\u001b[38;5;241m=\u001b[39mpickle_protocol)\n\u001b[1;32m    830\u001b[0m pickler\u001b[38;5;241m.\u001b[39mpersistent_id \u001b[38;5;241m=\u001b[39m persistent_id\n\u001b[0;32m--> 831\u001b[0m \u001b[43mpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    832\u001b[0m data_value \u001b[38;5;241m=\u001b[39m data_buf\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[1;32m    833\u001b[0m zip_file\u001b[38;5;241m.\u001b[39mwrite_record(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, data_value, \u001b[38;5;28mlen\u001b[39m(data_value))\n",
      "\u001b[0;31mPicklingError\u001b[0m: Can't pickle <class 'abc.BertForSequenceClassification'>: attribute lookup BertForSequenceClassification on abc failed"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "model.to(device)\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_correct = 0\n",
    "    for batch in imdb_train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids, attention_mask, labels = tuple(t.to(device) for t in batch)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "        train_loss += loss.item()\n",
    "        train_correct += (logits.argmax(dim=1) == labels).float().sum().item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    train_loss /= len(imdb_train_loader)\n",
    "    train_accuracy = train_correct / len(imdb_train)\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_correct = 0\n",
    "        for batch in imdb_test_loader:\n",
    "            input_ids, attention_mask, labels = tuple(t.to(device) for t in batch)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            test_correct += (logits.argmax(dim=1) == labels).float().sum().item()\n",
    "        test_accuracy = test_correct / len(imdb_test)\n",
    "        test_accuracies.append(test_accuracy)\n",
    "    print(f\"Epoch {epoch + 1}: train_loss={train_loss:.4f}, train_accuracy={train_accuracy:.4f}, test_accuracy={test_accuracy:.4f}\")\n",
    "\n",
    "torch.save(model, f\"adapter_bert_arxiv.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the sake of this demonstration an example path for loading and storing is given below\n",
    "save_path = os.path.join(os.getcwd(), \"adapter_bert\")\n",
    "\n",
    "# Save models\n",
    "model.save_pretrained(save_path)\n",
    "# Save adapter\n",
    "model.save_adapter(save_path, adapter_name=\"arxiv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for BertAdapterModel:\n\tsize mismatch for heads.default.1.weight: copying a param with shape torch.Size([2, 768]) from checkpoint, the shape in current model is torch.Size([10, 768]).\n\tsize mismatch for heads.default.1.bias: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([10]).\n\tYou may consider adding `ignore_mismatched_sizes=True` in the model `from_pretrained` method.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m saved_model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoAdapterModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m saved_model\u001b[38;5;241m.\u001b[39mload_adapter(save_path)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mbert\u001b[38;5;241m.\u001b[39mparameters():\n",
      "File \u001b[0;32m~/miniconda3/envs/rcfda/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:566\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    565\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 566\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    572\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/rcfda/lib/python3.10/site-packages/transformers/modeling_utils.py:3480\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3471\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3472\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[1;32m   3473\u001b[0m     (\n\u001b[1;32m   3474\u001b[0m         model,\n\u001b[1;32m   3475\u001b[0m         missing_keys,\n\u001b[1;32m   3476\u001b[0m         unexpected_keys,\n\u001b[1;32m   3477\u001b[0m         mismatched_keys,\n\u001b[1;32m   3478\u001b[0m         offload_index,\n\u001b[1;32m   3479\u001b[0m         error_msgs,\n\u001b[0;32m-> 3480\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloaded_state_dict_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# XXX: rename?\u001b[39;49;00m\n\u001b[1;32m   3484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3485\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3486\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3487\u001b[0m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3488\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_fast_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fast_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3491\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3492\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_quantized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquantization_method\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mQuantizationMethod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBITS_AND_BYTES\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3496\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3498\u001b[0m model\u001b[38;5;241m.\u001b[39mis_loaded_in_4bit \u001b[38;5;241m=\u001b[39m load_in_4bit\n\u001b[1;32m   3499\u001b[0m model\u001b[38;5;241m.\u001b[39mis_loaded_in_8bit \u001b[38;5;241m=\u001b[39m load_in_8bit\n",
      "File \u001b[0;32m~/miniconda3/envs/rcfda/lib/python3.10/site-packages/adapters/heads/base.py:969\u001b[0m, in \u001b[0;36mModelWithFlexibleHeadsAdaptersMixin._load_pretrained_model\u001b[0;34m(cls, model, state_dict, loaded_keys, *args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m         state_dict[k] \u001b[38;5;241m=\u001b[39m new_head_state_dict[k]\n\u001b[1;32m    967\u001b[0m         loaded_keys\u001b[38;5;241m.\u001b[39mappend(k)\n\u001b[0;32m--> 969\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloaded_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rcfda/lib/python3.10/site-packages/transformers/modeling_utils.py:3931\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[0;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, is_quantized, keep_in_fp32_modules)\u001b[0m\n\u001b[1;32m   3927\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize mismatch\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m error_msg:\n\u001b[1;32m   3928\u001b[0m         error_msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   3929\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mYou may consider adding `ignore_mismatched_sizes=True` in the model `from_pretrained` method.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3930\u001b[0m         )\n\u001b[0;32m-> 3931\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00merror_msg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3933\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_quantized:\n\u001b[1;32m   3934\u001b[0m     unexpected_keys \u001b[38;5;241m=\u001b[39m [elem \u001b[38;5;28;01mfor\u001b[39;00m elem \u001b[38;5;129;01min\u001b[39;00m unexpected_keys \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSCB\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m elem]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for BertAdapterModel:\n\tsize mismatch for heads.default.1.weight: copying a param with shape torch.Size([2, 768]) from checkpoint, the shape in current model is torch.Size([10, 768]).\n\tsize mismatch for heads.default.1.bias: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([10]).\n\tYou may consider adding `ignore_mismatched_sizes=True` in the model `from_pretrained` method."
     ]
    }
   ],
   "source": [
    "saved_model = AutoAdapterModel.from_pretrained(save_path)\n",
    "saved_model.load_adapter(save_path)\n",
    "\n",
    "for param in model.bert.parameters():\n",
    "    param.requires_grad = False\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    imdb_correct = 0\n",
    "    with tqdm(total=len(imdb_test_loader), desc='testing') as pbar:\n",
    "        for batch in imdb_test_loader:\n",
    "            input_ids, attention_mask, labels = tuple(t.to(device) for t in batch)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            imdb_correct += (logits.argmax(dim=1) == labels).float().sum().item()\n",
    "            pbar.update(1)\n",
    "        imdb_accuracy = imdb_correct / len(imdb_test)\n",
    "\n",
    "print('imdb bert vanilla accuracy:', imdb_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the last layer to perform 2 label classification\n",
    "model.classifier = torch.nn.Linear(768, 2)\n",
    "# Freeze the parameters of the pre-trained layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the modified model for 2 label classification\n",
    "outputs = model(input_ids, attention_mask)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rcfda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
